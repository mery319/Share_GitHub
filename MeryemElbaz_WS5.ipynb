{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worksheet 5: Discover the Higgs Boson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original work statement: \n",
    "\n",
    "Please write your name here to indicate that your worksheet is the result of your own work, and you have not copied from sources without citing them (this is plagiarism and is not acceptable). Identical or very similar worksheet will share the credit.\n",
    "\n",
    "#### Your name: Meryem El baz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this worksheet, we provide you with a (simplified) version of the simulated Higgs boson data challenge, run by Kaggle in 2014. The files are called \"Higgs_features.csv\" and \"Higgs_labels.csv\". The labels are 0 and 1, corresponding to \"no Higgs signal\", and \"Higgs signal\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Read the data into two numpy arrays, one for features and one for labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 393.335   79.46   308.879 ...   -1.411   49.063   39.478]\n",
      " [  71.048   29.291   55.602 ...   -1.412   22.926    9.486]\n",
      " [ 141.45    87.017   72.091 ...    1.233   23.591   69.754]\n",
      " ...\n",
      " [  78.421   51.766   51.303 ...    1.108   26.775   30.509]\n",
      " [  90.507   70.86    75.535 ...   -1.41    45.511   27.279]\n",
      " [-999.      71.491   35.996 ...   -1.395   20.52    44.2  ]]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.genfromtxt('Higgs_features.txt', delimiter=\",\")\n",
    "y=np.genfromtxt('Higgs_labels.txt', delimiter=\",\")\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many instances and features are in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we have 25000 instances and 8 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Plot the distribution of each feature for this data set in a histogram (like we did in on of the previous worksheets), in one plot. Add a legend (with labels \"Feature 1\", \"Feature 2\"...) and set the transparency of the histograms (property \"alpha\") to 0.5 for clarity. Hint: make sure you are plotting each column, not each row!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2017c9d4710>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(x.shape[1]):\n",
    "    plt.hist(x[:,i],alpha=0.5,histtype='stepfilled',label = 'Feature'+str(i+1));\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Do you see anything unusual in the distribution of any of the features? What problem could this cause?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We have an important number of outliers marked as -999. This might affect the performnce our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. How many positive (Higgs) events does your data set contain? Based on this, is the data set balanced or unbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182768, 17225)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(x > 0), np.sum(x < 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "No, I think it's unbalanced because we have so many positive features compared to the negative one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. On the basis of your answer to 5, which evaluation metric (accuracy, precision, recall) would you like to pick for this data set?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Because of our unbalanced data, it's better to use the recall score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Use a decision tree classifier as your model, and do five fold cross validation on your data, <b> using the scoring parameter you chose above</b>. Report the mean and standard deviation of the scores obtained for the five folds.\n",
    "\n",
    "Note: If you simply set the parameter \"cv = 5\" in the cross_val_score function, this will divide the data in five sets using the first 20%, second 20%... etc of your data, which is not great if your data are in a specific order. Make sure you use cv = StratifiedKFold(shuffle=True, n_splits=5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64955752 0.64483776 0.62536873 0.63185841 0.65466352]\n",
      "0.6412571874357875\n",
      "0.010974751493599125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "model = DecisionTreeClassifier()\n",
    "scores = cross_val_score(model, x, y, cv=StratifiedKFold(shuffle=True, n_splits=5), scoring='recall') \n",
    "print(scores) \n",
    "print(np.mean(scores))\n",
    "print(np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. We want to now take a look at the confusion matrix for your classifier. When doing cross validation, sklearn offers a function called cross_val_predict that allows you to save the vector with the predicted values when each object is part of the test set. (http://scikit-learn.org/stable/modules/cross_validation.html). The code for doing that follows; of course you will have to change the name of the model (algorithm) and of the arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. ... 0. 0. 0.]\n",
      "[[13435  3091]\n",
      " [ 3091  5383]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "\n",
    "predicted = cross_val_predict(model, x, y, cv=StratifiedKFold(shuffle=True, n_splits=5))\n",
    "print(predicted)\n",
    "print(metrics.confusion_matrix(y, predicted)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. Given your confusion matrix, how many true positives / true negatives / false positives / false negatives are there? Do you have many more type I errors (false positives) than type II errors (false negatives)?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "true positive=5383\n",
    "true negative=13435\n",
    "false positive=3091\n",
    "false negative=3091\n",
    "I got the saame number of false positive and false negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Let's now switch to a SVC classifier. Leaving the parameters of the classifier at their default values, run a five-fold cross validation and report the scores just like you did above for the decision tree. (Note: SVMs are slow so this might take some time, a good 5 minutes on my laptop). Which algorithm performs better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "scores = cross_val_score(model, x, y, cv=StratifiedKFold(shuffle=True, n_splits=5), scoring='recall') \n",
    "print(scores) \n",
    "print(np.mean(scores))\n",
    "print(np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11\\. Report the confusion matrix for the SVC algorithm. Do you notice a change in the distribution of the false positives and false negatives, with respect to the decision tree algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\merye\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\merye\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\merye\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\merye\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\merye\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "predicted2 = cross_val_predict(model, x, y, cv=StratifiedKFold(shuffle=True, n_splits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cnf_matrix = confusion_matrix(y, predicted2)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['0','1'],\n",
    "                      title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12\\. We can now do the nested cross validation to optimize the parameters of the SVC. Because it would otherwise take a long time, we can select the first 10% of the data set (after shuffling the data set). We did something like this when we were doing learning curves in Worksheet 4 (questions 11 and 12). Select the first 10% of the data set, both for feature and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_samples = x.shape[0]\n",
    "from sklearn.utils import shuffle\n",
    "x, y = shuffle(x, y, random_state=10)\n",
    "xlittle, ylittle = x[:int(number_samples*0.01),:], y[:int(number_samples*0.01)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13\\. Set up and run a nested cross validation with 5 outer folds and 3 inner folds. Your GridSearch CV will have the following parameters: \n",
    "\n",
    "parameters = {'kernel':['linear','rbf'],'C':[1, 10, 100], 'gamma':[0.01, 0.1, 0.5], 'class_weight':[{1:1},{1:3},{1:5}]}\n",
    "\n",
    "You can use the last example (\"putting them all together\") from the SVMs and Hyperparameter fitting notebook, but remember to change the scoring parameter to match what you did above.\n",
    "\n",
    "Note: this might take time! Set verbose = 2 in the GridSearchCV to follow the progress, and set njobs = 4 or more to speed up the process. If your machine can't handle it, you can reduce the size of the data set to 5% of the original. \n",
    "\n",
    "#### Report the scores and parameters values of the best model.\n",
    "\n",
    "Note: some times that code has given me an issue of creating \"Nan\" in the ylittle_train arrays. If this happens, you can try substituting the lines\n",
    "\n",
    "ylittle_train = ylittle[train_index]\n",
    "ylittle_test = ylittle[test_index]\n",
    "    \n",
    "with \n",
    "\n",
    "ylittle_train = ylittle.iloc[train_index]\n",
    "ylittle_test = ylittle.iloc[test_index]\n",
    "\n",
    "(see https://stackoverflow.com/questions/39376967/nans-suddenly-appearing-for-sklearn-kfolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 outer cross validation\n",
      "Fitting 4 folds for each of 54 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=4)]: Done 216 out of 216 | elapsed: 15.1min finished\n",
      "C:\\Users\\merye\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params, best score: 0.9860 {'C': 1, 'class_weight': {1: 5}, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "Time per model (s): 4.2135\n",
      "Fold  2 outer cross validation\n",
      "Fitting 4 folds for each of 54 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 183 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=4)]: Done 216 out of 216 | elapsed: 17.3min finished\n",
      "C:\\Users\\merye\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params, best score: 0.9861 {'C': 1, 'class_weight': {1: 5}, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "Time per model (s): 4.8671\n",
      "Fold  3 outer cross validation\n",
      "Fitting 4 folds for each of 54 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done 156 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=4)]: Done 216 out of 216 | elapsed: 16.5min finished\n",
      "C:\\Users\\merye\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params, best score: 0.9575 {'C': 1, 'class_weight': {1: 5}, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "Time per model (s): 4.6078\n"
     ]
    }
   ],
   "source": [
    "#Important! COMMENT\n",
    "\n",
    "#Outer k-fold:\n",
    "import time\n",
    "outercv = StratifiedKFold(n_splits=5, shuffle=True) #creates 5 disjoint splits\n",
    "\n",
    "innercv = StratifiedKFold(n_splits=4, shuffle=True) #creates 4 disjoint splits\n",
    "\n",
    "i=0\n",
    "\n",
    "winning_model_scores = []\n",
    "\n",
    "for train_index, test_index in outercv.split(xlittle,ylittle): #This runs the outer cross validation\n",
    "    \n",
    "    i+=1\n",
    "    \n",
    "    print('Fold ' ,i, 'outer cross validation')\n",
    "    \n",
    "    Xlittle_train = xlittle[train_index] #\"yellow\" training set\n",
    "    ylittle_train = ylittle[train_index]\n",
    "    \n",
    "    Xlittle_test = xlittle[test_index]\n",
    "    ylittle_test = ylittle[test_index]\n",
    "    \n",
    "    #optimizing SVC: this replaces the inner loop!\n",
    "    \n",
    "    parameters = {'kernel':['rbf','linear'],'gamma':[0.01, 0.05, 0.1], 'C':[1,10,100],\\\n",
    "                  'class_weight':[{1:1},{1:3},{1:5}]}\n",
    "    nmodels = np.product([len(el) for el in parameters.values()])\n",
    "    start = time.time()\n",
    "    model = GridSearchCV(SVC(), parameters, cv = innercv, scoring = 'recall', \\\n",
    "                     verbose = 2, n_jobs = 4)\n",
    "    model.fit(Xlittle_train, ylittle_train)\n",
    "    stop = time.time()\n",
    "    print('Best params, best score:', \"{:.4f}\".format(model.best_score_), model.best_params_)\n",
    "    print('Time per model (s):', \"{:.4f}\".format((stop-start)/float(nmodels*4)))\n",
    "\n",
    "    #Compute test scores with optimal parameters on outer i-th test fold\n",
    "    \n",
    "    winner = model.best_estimator_\n",
    "    \n",
    "    winner.fit(Xlittle_train, ylittle_train)\n",
    "    \n",
    "    ypred = winner.predict(Xlittle_test)\n",
    "    \n",
    "    winning_model_scores.append(metrics.recall_score(ylittle_test,ypred)) #append this to the outer cv results\n",
    "    \n",
    "print('The average of the winning model scores (i.e. the generalization error) is', \\\n",
    "      np.mean(winning_model_scores), np.std(winning_model_scores) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15\\. Now that you have optimized the parameters, you can run the 5 fold cross validation on the original data set, basically what you did in 10., but fixing the parameter values at the \"optimal values\" found above (i.e., choose the model that was most often selected as the winner model). What are the mean and standard deviation of the scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "?SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC(C= 1, class_weight= {1: 5}, gamma= 0.01, kernel= 'linear')\n",
    "scores = cross_val_score(model, x, y, cv=StratifiedKFold(shuffle=True, n_splits=5), scoring='recall',n_jobs=6) \n",
    "print(scores) \n",
    "print(np.mean(scores))\n",
    "print(np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16\\. Based on what you found, would you recommend to use a Decision Tree Classifier or a Support Vector Classifier for this problem?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Based on the results I got, I think that the SVC with parameter optimization is much better than the Decision Tree Classifier, because we get better scores and the performance is better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra Credit: The object GridSearchCV (probably called clf in your code) that you created in 13. has an attribute \"grid\\_scores\\_\" that allows you to visualize the scores for every combination of parameters (if you are using sklearn version 0.19 and above, the attribute is named cv\\_results\\_). Based on this, which parameter has the highest impact (induces the largest change) on the performance of the SVC? Do you think it might be worth optimizing it further?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From Question 13, Ibelieve that the class's weight has more impact on the performance of the SVC. I don't think that it's worth optimizing because we did reach good scores with the parameter that we have chosen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
